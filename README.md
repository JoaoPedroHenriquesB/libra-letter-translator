# ğŸ¤Ÿ Tradutor de Libras (LIBRAS Translator)

Um projeto de reconhecimento de gestos em tempo real para traduÃ§Ã£o da LÃ­ngua Brasileira de Sinais (LIBRAS) usando visÃ£o computacional e aprendizado de mÃ¡quina.

## ğŸ“‹ Sobre o Projeto

Este projeto utiliza OpenCV e MediaPipe para capturar e analisar movimentos das mÃ£os atravÃ©s da webcam, identificando letras do alfabeto em LIBRAS. O sistema Ã© capaz de reconhecer tanto gestos estÃ¡ticos quanto dinÃ¢micos (que envolvem movimento).

### âš ï¸ Status do Projeto

**ğŸš§ PROJETO EM DESENVOLVIMENTO ğŸš§**

Este projeto ainda estÃ¡ em fase de desenvolvimento e nÃ£o estÃ¡ completo. Funcionalidades implementadas e limitaÃ§Ãµes:

#### âœ… Funcionalidades Implementadas:
- Captura de vÃ­deo em tempo real via webcam
- DetecÃ§Ã£o e rastreamento de landmarks das mÃ£os usando MediaPipe
- Reconhecimento de letras estÃ¡ticas do alfabeto LIBRAS
- Reconhecimento de letras dinÃ¢micas (J, H, Z, X) que requerem movimento
- Sistema de coleta e armazenamento de dados de treinamento
- Interface visual com feedback em tempo real

#### âŒ Limitaï¿½ï¿½Ãµes Atuais:
- Conjunto limitado de letras reconhecidas
- PrecisÃ£o pode variar dependendo da iluminaÃ§Ã£o e posicionamento
- NÃ£o possui interface grÃ¡fica amigÃ¡vel
- Falta de reconhecimento de palavras completas
- AusÃªncia de traduÃ§Ã£o de frases
- NÃ£o possui sistema de calibraÃ§Ã£o personalizada

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.x**
- **OpenCV** - Processamento de imagem e vÃ­deo
- **MediaPipe** - DetecÃ§Ã£o de landmarks das mÃ£os
- **NumPy** - OperaÃ§Ãµes matemÃ¡ticas e processamento de arrays
- **JSON** - Armazenamento de dados de landmarks

## ğŸ“¦ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone [URL_DO_REPOSITORIO]
cd tradutor-de-libras
```

2. Crie um ambiente virtual (recomendado):
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸš€ Como Usar

### Executar o Reconhecimento em Tempo Real:
```bash
python camera.py
```

### Controles:
- **'q'** - Sair do programa
- **'s'** - Salvar landmarks da mÃ£o atual (para treinamento)

### Testar Movimentos EspecÃ­ficos:
```bash
python test_movements.py
```

## ğŸ“ Estrutura do Projeto

```
tradutor-de-libras/
â”œâ”€â”€ camera.py                 # Script principal de captura e reconhecimento
â”œâ”€â”€ gestures.py              # LÃ³gica de detecÃ§Ã£o de gestos e movimentos
â”œâ”€â”€ test_movements.py        # Testes para movimentos especÃ­ficos
â”œâ”€â”€ configuracao_avancada.py # ConfiguraÃ§Ãµes avanÃ§adas do sistema
â”œâ”€â”€ requirements.txt         # DependÃªncias do projeto
â”œâ”€â”€ landmarks/              # Dados de treinamento salvos
â”‚   â””â”€â”€ all_landmarks.json  # Landmarks coletados para cada letra
â”œâ”€â”€ shape_predictor_68_face_landmarks.dat # Modelo para detecÃ§Ã£o facial
â””â”€â”€ README.md               # Este arquivo
```

## ğŸ¯ Funcionalidades Detalhadas

### Reconhecimento EstÃ¡tico
- Identifica letras baseadas na posiÃ§Ã£o dos dedos
- Utiliza normalizaÃ§Ã£o de landmarks para maior precisÃ£o
- Compara com banco de dados de gestos prÃ©-coletados

### Reconhecimento DinÃ¢mico
- **Letra J**: Movimento em gancho para baixo e esquerda
- **Letra H**: Movimento horizontal da direita para esquerda
- **Letra Z**: Movimento em zigue-zague
- **Letra X**: Movimento de gancho pequeno

### Sistema de Coleta de Dados
- Permite salvar novos exemplos de gestos
- Armazena landmarks em formato JSON
- Suporte para mÃºltiplas amostras por letra

## ğŸ”® PrÃ³ximos Passos

- [ ] Expandir o alfabeto completo de LIBRAS
- [ ] Implementar reconhecimento de nÃºmeros
- [ ] Adicionar suporte para palavras e frases
- [ ] Criar interface grÃ¡fica mais amigÃ¡vel
- [ ] Melhorar precisÃ£o com mais dados de treinamento
- [ ] Implementar sistema de calibraÃ§Ã£o personalizada
- [ ] Adicionar suporte para mÃºltiplas mÃ£os simultaneamente
- [ ] Criar sistema de traduÃ§Ã£o bidirecional (texto para LIBRAS)

## ğŸ¤ Contribuindo

Este projeto estÃ¡ aberto para contribuiÃ§Ãµes! Se vocÃª quiser ajudar:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ Contato

JoÃ£o Pedro Henriques Balbino - joaopedrohbalbino@gmail.com

**Nota**: Este Ã© um projeto educacional/experimental em desenvolvimento. Para uso em produÃ§Ã£o, sÃ£o necessÃ¡rios mais testes e melhorias na precisÃ£o do reconhecimento.
